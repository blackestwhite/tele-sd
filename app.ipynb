{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion + Telegram bot\n",
    "[Github Repo](https://github.com/blackestwhite/tele-sd)\n",
    "\n",
    "## Donations\n",
    "Ethereum: `0xE76fc1CE4d3ffFEA12A5686618844408C327357b`\n",
    "\n",
    "## steps\n",
    "- create a telegram bot\n",
    "- set the token on the code\n",
    "- run all\n",
    "\n",
    "\n",
    "## How to use\n",
    "go to your bot on telegram send the Prompts separated by `__`, (two underscores).\n",
    "before the separator will be the positive prompt, after that will be the negative prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drivePath = '/content/drive'\n",
    "\n",
    "if os.path.isdir(drivePath) == False:\n",
    "    drive.mount(drivePath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet nest-asyncio transformers diffusers python-telegram-bot accelerate triton scipy ftfy spacy xformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Setup Bot + SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telegram import Update, Bot\n",
    "from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes, MessageHandler, filters\n",
    "import nest_asyncio\n",
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "import asyncio\n",
    "import random\n",
    "\n",
    "base = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "base.to(\"cuda\")\n",
    "refiner = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
    "    text_encoder_2=base.text_encoder_2,\n",
    "    vae=base.vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\",\n",
    ")\n",
    "refiner.to(\"cuda\")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "token = \"Your Telegram Bot Token Here\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Handler for bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_steps = 40\n",
    "high_noise_frac = 0.8\n",
    "\n",
    "async def generate(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "  text = update.message.text\n",
    "  text = text.replace(\"\\n\", \"\")\n",
    "  prompt = ''\n",
    "  neg = ''\n",
    "  if '__' in text:\n",
    "    prompt = text.split(\"__\")[0]\n",
    "    neg = text.split(\"__\")[1]\n",
    "  else:\n",
    "    prompt = text\n",
    "  seed = random.randint(0, 2147483647)\n",
    "  image = base(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=neg,\n",
    "    num_inference_steps=default_steps,\n",
    "    denoising_end=high_noise_frac,\n",
    "    output_type=\"latent\",\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "  ).images\n",
    "  image = refiner(\n",
    "      prompt=prompt,\n",
    "      num_inference_steps=default_steps,\n",
    "      denoising_start=high_noise_frac,\n",
    "      image=image,\n",
    "  ).images[0]\n",
    "  image.save(\"./image.png\")\n",
    "  await update.message.reply_photo(photo=\"./image.png\")\n",
    "\n",
    "app = ApplicationBuilder().token(token).build()\n",
    "\n",
    "app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, generate))\n",
    "\n",
    "app.run_polling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
